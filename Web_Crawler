import re

from urllib import request



class Crawler():

    url = 'https://www.panda.tv/cate/hearthstone'

    root_pattern = '<div class="video-info">([\s\S]*?)</div>'

    name_pattern = '</i>([\s\S]*?)</span>'

    number_patter = '<span class="video-number">([\s\S]*?)</span>'

    VideoContent = 'class="video-title">([\s\S]*?)</span>'



    def __fetch_content(self):

        #headers ={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299'}

        #req=request(Crawler.url)
        htmls = request.urlopen(Crawler.url).read()

        htmls = str(htmls, encoding='utf-8')

        return htmls



    def __anlysis(self, htmls):

        root_html = re.findall(Crawler.root_pattern, htmls)

        anchors = []

        for html in root_html:

            name = re.findall(Crawler.name_pattern, html)

            number = re.findall(Crawler.number_patter, html)

            anchor = {'name':name, 'number':number}

            anchors.append(anchor)

        lab = lambda anchor: {'name': anchor['name'][0].strip(),

                            'number': anchor['number'][0]

                             }
        print(anchors)
        anchors=map(lab, anchors)

        return anchors

    def __sort_seed(self, anchor):

        r = re.findall('\d*', anchor['number'])

        number = float(r[0])

        if 'ä¸‡' in anchor['number']:

            number *= 10000

        return number



    def __sort(self, anchors):

        anchors = sorted(anchors, key=self.__sort_seed, reverse=True)

        return anchors


    def __show(self, anchors):

        for rank in range(0, len(anchors)):

            print('rank ' + str(rank+1)

                  +'  : '+ anchors[rank]['name']

                  +'   ' + anchors[rank]['number'])



    def go(self):

        htmls = self.__fetch_content()

        anchors = self.__anlysis(htmls)

        anchors = self.__sort(anchors)

        self.__show(anchors)



Crawlers = Crawler()

Crawlers.go()
